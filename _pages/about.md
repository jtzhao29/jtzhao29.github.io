---
permalink: /
# title: "Academic Pages is a ready-to-fork GitHub Pages template for academic personal websites"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am a undergraduate majoring in Physics at Shanghai Jiaotong University, with a great interst in AI. 

See [Research interests](#research-interests) part for more information about what I am intersted. If you share a similar passion with me, feel free to reach out and connect with me!

<!-- ## Education
- BSc in Physics, Shanghai Jiaotong University, 2027 (Expected) -->

## Research interests

I mainly focus on how to enable models to emergently develop **generalized reasoning abilities at a sustainale scale with RL**. I believe that as the scale of systems increases, whether a model can emergently develop generalized reasoning abilities without relying on external supervision is a key step toward AGI. My research interests in this area include:

1. Emergent Reasoning Ability: 
  - Given that SFT memories, while RL improves model's ability of combining "auto skills"[^1] [^2], is it possible to maximize a model's exploration and reasoning abilities purely through RL? Could **pure RL drive the emergence of reasoning** without any pre-defined structure?
  - Is the current Chain-of-Thought (CoT) the real "CoT"[^3]? Can **RL alone make latent reasoning emerge as CoT** by itself?

[^1]: [SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training](https://arxiv.org/pdf/2501.17161)

[^2]: [From f(x) and g(x) to f(g(x)): LLMs Learn New Skills in RL by Composing Old Ones](https://husky-morocco-f72.notion.site/From-f-x-and-g-x-to-f-g-x-LLMs-Learn-New-Skills-in-RL-by-Composing-Old-Ones-2499aba4486f802c8108e76a12af3020)

[^3]: [Reasoning models don't always say what they think](https://www.anthropic.com/research/reasoning-models-dont-say-think)



2. AI + formal verifier system: 
  - I am interested in building scalable solutions where AI systems can autonomously verify their own reasoning and results through interaction with a verifier system(**PLVR**)[^4]. This approach does not rely on the amount of existing data but leverages the verifier to guide the model's learning process, which might be a potential pathway to achieving scalability.
  - How to design task generation mechanisms that push the model to propose tasks that are tough but not too difficult. This touches on concepts like curriculum learning or **auto self-play**.

[^4]: [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org/abs/2505.03335)






## Research experience

- July 2025 - Present: Research Intern @ Big AI Dream Lab, Shanghai AI Lab. Supervised by [Jie Fu](https://bigaidream.github.io/)

- March 2025 - May 2025: Research Intern Supervised by Prof.[Junchi Yan](https://thinklab.sjtu.edu.cn/) and Prof.[Renxiu Xia](https://scholar.google.com/citations?user=E520fqQAAAAJ&hl=zh-CN) @ SAI, Shanghai Jiaotong University
  - 这里详细说一下：TBD
  - 

- Augest 2024: Research Assistant in [Zhangjiang National Lab](https://www.zjlab.ac.cn/), where I completed an AI4PHY project on my own. 





